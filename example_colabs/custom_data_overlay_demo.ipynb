{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MDUUcFa7O2u"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-ai-edge/model-explorer/blob/main/example_colabs/custom_data_overlay_demo.ipynb)\n",
        "\n",
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "me12eMftdu4H",
        "outputId": "df0b5bef-a765-447c-e5b9-b9a87cadf709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.21.0.dev20250925-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=25.2.10 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (25.0)\n",
            "Collecting protobuf<8.0.0,>=6.31.1 (from tf-nightly)\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (1.75.0)\n",
            "Collecting tb-nightly~=2.20.0.a (from tf-nightly)\n",
            "  Downloading tb_nightly-2.20.0a20250717-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting keras-nightly>=3.10.0.dev (from tf-nightly)\n",
            "  Downloading keras_nightly-3.12.0.dev2025092803-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tf-nightly) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly) (3.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.20.0.a->tf-nightly) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras-nightly>=3.10.0.dev->tf-nightly) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras-nightly>=3.10.0.dev->tf-nightly) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.10.0.dev->tf-nightly) (0.1.2)\n",
            "Downloading tf_nightly-2.21.0.dev20250925-cp312-cp312-manylinux_2_27_x86_64.whl (556.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.3/556.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nightly-3.12.0.dev2025092803-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tb_nightly-2.20.0a20250717-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, tb-nightly, keras-nightly, tf-nightly\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-nightly-3.12.0.dev2025092803 protobuf-6.32.1 tb-nightly-2.20.0a20250717 tf-nightly-2.21.0.dev20250925\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "145fe9fba9a04177a197d16857ad5053"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ai-edge-model-explorer\n",
            "  Downloading ai_edge_model_explorer-0.1.26-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ai-edge-model-explorer-adapter\n",
            "  Downloading ai_edge_model_explorer_adapter-0.1.12-cp312-cp312-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading ai_edge_model_explorer-0.1.26-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ai_edge_model_explorer_adapter-0.1.12-cp312-cp312-manylinux_2_17_x86_64.whl (90.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ai-edge-model-explorer-adapter, ai-edge-model-explorer\n",
            "Successfully installed ai-edge-model-explorer-0.1.26 ai-edge-model-explorer-adapter-0.1.12\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n"
          ]
        }
      ],
      "source": [
        "# Install tf-nightly & model-explorer.\n",
        "!pip install tf-nightly\n",
        "!pip install --no-deps ai-edge-model-explorer ai-edge-model-explorer-adapter\n",
        "\n",
        "# Install kagglehub (will be used in the next step to download a model)\n",
        "!pip install kagglehub --no-deps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im5BQ2Qz7na_"
      },
      "source": [
        "# Download MobileNet v3 from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xaSxh0rQf4Fj",
        "outputId": "47806c1c-8b7c-4093-a8d8-35166828cf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "30af8ddde43144748f309b76725b214f",
            "201f52c30c1c4584bf2b909cb503f72c",
            "9475ecfb06444fe3b8e295f29e157115",
            "c6cb0e00b0754cfd8bb5c2d3e4be23c8",
            "178855b63dfe4ab69c87509953e45d78",
            "d7718eec277e40f89a9fdaff15ea2fad",
            "27260582510c4eac9a7527412d6c981d",
            "e0e6f38cb60f4d1c8b863e3c757292fc",
            "c4b28902880540d39c35fcd62c13a590",
            "1da90197ffce4bc3ab5c786afbe78cfd",
            "c5877353e91f4fd19cd667383bfa1476"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30af8ddde43144748f309b76725b214f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/google/mobilenet-v3/tfLite/large-075-224-classification/1/download/1.tflite...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0.00/15.3M [00:00<?, ?B/s]\u001b[A\n",
            " 33%|███▎      | 5.00M/15.3M [00:00<00:00, 50.4MB/s]\u001b[A\n",
            "100%|██████████| 15.3M/15.3M [00:00<00:00, 52.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# This demo uses MobileNet v3, but you can use other models as well\n",
        "path = kagglehub.model_download(\n",
        "    \"google/mobilenet-v3/tfLite/large-075-224-classification\"\n",
        ")\n",
        "model_path = f\"{path}/1.tflite\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWm4BE_I70hi"
      },
      "source": [
        "# Run the model with test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6cuAg62OvfTK",
        "outputId": "ee7e9396-6343-4e9b-83fe-07a86b4c53d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "/usr/local/lib/python3.12/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow15TensorShapeBaseINS_11TensorShapeEEC2EN4absl12lts_202308024SpanIKlEE",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1181480276.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the TFLite model and allocate tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0m_kernel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tf_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kernels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_kernel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0m_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_kernel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;31m# Load third party dynamic kernels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_libraries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /usr/local/lib/python3.12/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow15TensorShapeBaseINS_11TensorShapeEEC2EN4absl12lts_202308024SpanIKlEE"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Generate random input data.\n",
        "for input_detail in input_details:\n",
        "  input_shape = input_detail['shape']\n",
        "  input_data = np.array(\n",
        "      np.random.random_sample(input_shape), dtype=input_detail['dtype']\n",
        "  )\n",
        "  interpreter.set_tensor(input_detail['index'], input_data)\n",
        "\n",
        "# Run the model on random input data.\n",
        "interpreter.invoke()\n",
        "\n",
        "# Examine the output data (optional)\n",
        "for output_detail in output_details:\n",
        "  print(f\"Output for {output_detail['name']}\")\n",
        "  output_data = interpreter.get_tensor(output_detail['index'])\n",
        "  print(output_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhwvzBUIO9SZ"
      },
      "source": [
        "# Prepare per-op benchmarking data for Model Explorer\n",
        "## Step 1: Run the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2FLsz9OsC6w_"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /tmp/data\n",
        "\n",
        "%cd /tmp/data\n",
        "\n",
        "CPU_PROFILING_PROTO_PATH = \"/tmp/data/mv3-cpu-op-profile.pb\"\n",
        "\n",
        "# In this example, we're using profiling data from Android's Benchmarking tools\n",
        "# that has already been mapped (outside of this Colab) to the Model Explorer schema.\n",
        "\n",
        "# You can overlay per-op data of your choice by following the instructions at\n",
        "# https://github.com/google/model-explorer/wiki/2.-User-Guide#custom-node-data\n",
        "\n",
        "%env MODEL_PATH=$model_path\n",
        "%env CPU_PROFILING_PROTO_PATH=$CPU_PROFILING_PROTO_PATH\n",
        "\n",
        "# Download the tflite model benchmark binary.\n",
        "!wget -nc https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model\n",
        "!chmod +x /tmp/data/linux_x86-64_benchmark_model\n",
        "\n",
        "# Run the benchmark locally only using CPU kernels with op_profiling enabled.\n",
        "!./linux_x86-64_benchmark_model --graph=$MODEL_PATH --use_xnnpack=false --num_threads=4 --enable_op_profiling=true --op_profiling_output_mode=proto --op_profiling_output_file=$CPU_PROFILING_PROTO_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7c4l0GNW-rF"
      },
      "source": [
        "## Step 2: Generate the per-op profiling JSON using benchmark results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fPIhMbbGW-rG",
        "outputId": "8d0ba850-a3d0-42df-ea45-b0d7509723f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CPU_PROFILING_PROTO_PATH' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4250658130.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Generate pure CPU per-op profiling JSON.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m generate_model_explorer_json(\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mCPU_PROFILING_PROTO_PATH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mCPU_PROFILING_JSON_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0m_PER_OP_LATENCY_JSON_TYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CPU_PROFILING_PROTO_PATH' is not defined"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "from collections.abc import Sequence\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from typing import Any, List\n",
        "\n",
        "from tensorflow.lite.profiling.proto import profiling_info_pb2\n",
        "\n",
        "_PER_OP_LATENCY_JSON_TYPE = \"per_op_latency\"\n",
        "_OP_TYPE_JSON_TYPE = \"op_type\"\n",
        "\n",
        "_MODEL_EXPLORER_JSON_TYPES = [_PER_OP_LATENCY_JSON_TYPE, _OP_TYPE_JSON_TYPE]\n",
        "\n",
        "\n",
        "def get_op_profile_json(\n",
        "    op_profile: profiling_info_pb2.OpProfileData,\n",
        "    model_explorer_json_type: str,\n",
        ") -> dict[str, Any]:\n",
        "  \"\"\"Generates the Model Explorer json for the op profile.\n",
        "\n",
        "  Args:\n",
        "    op_profile: profiling_info_pb2.OpProfileData\n",
        "    model_explorer_json_type: Type of model explorer json to generate.\n",
        "\n",
        "  Returns:\n",
        "    Model explorer json for the op profile.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If the op profile name is not in the expected format.\n",
        "    ValueError: If the model explorer json type is not supported.\n",
        "  \"\"\"\n",
        "  op_profile_key_re = re.findall(r\":(\\d+)$\", op_profile.name)\n",
        "  if not op_profile_key_re:\n",
        "    raise ValueError(\"Op profile name is not in the expected format.\")\n",
        "  op_profile_key = op_profile_key_re[0]\n",
        "\n",
        "  if model_explorer_json_type == _PER_OP_LATENCY_JSON_TYPE:\n",
        "    return {\n",
        "        op_profile_key: {\n",
        "            \"value\": op_profile.inference_microseconds.avg / 1000.0\n",
        "        }\n",
        "    }\n",
        "  elif model_explorer_json_type == _OP_TYPE_JSON_TYPE:\n",
        "    return {op_profile_key: {\"value\": op_profile.node_type}}\n",
        "  else:\n",
        "    raise ValueError(\n",
        "        \"Unsupported model explorer json type: %s\" % model_explorer_json_type\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_model_explorer_json(\n",
        "    benchmark_profiling_proto_paths: List[str],\n",
        "    output_path: str,\n",
        "    model_explorer_json_type: str,\n",
        ") -> dict[str, Any]:\n",
        "  \"\"\"Generates the Model Explorer json for the benchmark profiling proto.\"\"\"\n",
        "  if not benchmark_profiling_proto_paths:\n",
        "    raise ValueError(\"At least one profiling proto path should be provided.\")\n",
        "\n",
        "  if model_explorer_json_type not in _MODEL_EXPLORER_JSON_TYPES:\n",
        "    raise ValueError(\n",
        "        f\"Unsupported model explorer json type: {model_explorer_json_type}\"\n",
        "    )\n",
        "\n",
        "  output_json = collections.defaultdict(dict)\n",
        "  for proto_path in benchmark_profiling_proto_paths:\n",
        "    if not os.path.isfile(proto_path):\n",
        "      raise ValueError(f\"File {proto_path} does not exist.\")\n",
        "\n",
        "    with open(proto_path, \"rb\") as f:\n",
        "      benchmark_profiling_proto = (\n",
        "          profiling_info_pb2.BenchmarkProfilingData.FromString(f.read())\n",
        "      )\n",
        "      for (\n",
        "          subgraph_profile\n",
        "      ) in benchmark_profiling_proto.runtime_profile.subgraph_profiles:\n",
        "        subgraph_profile_json = {}\n",
        "        for op_profile in subgraph_profile.per_op_profiles:\n",
        "          subgraph_profile_json.update(\n",
        "              get_op_profile_json(op_profile, model_explorer_json_type)\n",
        "          )\n",
        "        output_json[subgraph_profile.subgraph_name][\n",
        "            \"results\"\n",
        "        ] = subgraph_profile_json\n",
        "\n",
        "        if model_explorer_json_type == _PER_OP_LATENCY_JSON_TYPE:\n",
        "          output_json[subgraph_profile.subgraph_name][\"gradient\"] = [\n",
        "              {\"stop\": 0, \"bgColor\": \"green\"},\n",
        "              {\"stop\": 0.33, \"bgColor\": \"yellow\"},\n",
        "              {\"stop\": 0.67, \"bgColor\": \"orange\"},\n",
        "              {\"stop\": 1, \"bgColor\": \"red\"},\n",
        "          ]\n",
        "\n",
        "  if output_path:\n",
        "    with open(output_path, \"w\") as f:\n",
        "      json.dump(output_json, f)\n",
        "  else:\n",
        "    print(json.dumps(output_json, indent=2))\n",
        "\n",
        "\n",
        "CPU_PROFILING_JSON_PATH = \"/tmp/data/mv3-cpu-op-profile.json\"\n",
        "\n",
        "# Generate pure CPU per-op profiling JSON.\n",
        "generate_model_explorer_json(\n",
        "    [CPU_PROFILING_PROTO_PATH],\n",
        "    CPU_PROFILING_JSON_PATH,\n",
        "    _PER_OP_LATENCY_JSON_TYPE,\n",
        ")\n",
        "\n",
        "# Download the XNNPACK per-op profiling JSON from storage.\n",
        "!wget -nc https://storage.googleapis.com/tfweb/model-explorer-demo/mv3-xnnpack-op-profile.json\n",
        "XNNPACK_PROFILING_JSON_PATH = \"/tmp/data/mv3-xnnpack-op-profile.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCgFNFP4WAzE"
      },
      "source": [
        "# Visualize the model with per op latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SVyHrthM_hz"
      },
      "outputs": [],
      "source": [
        "import model_explorer\n",
        "\n",
        "config = model_explorer.config()\n",
        "(\n",
        "    config.add_model_from_path(model_path)\n",
        "    .add_node_data_from_path(CPU_PROFILING_JSON_PATH)\n",
        "    .add_node_data_from_path(XNNPACK_PROFILING_JSON_PATH)\n",
        ")\n",
        "\n",
        "model_explorer.visualize_from_config(config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30af8ddde43144748f309b76725b214f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_201f52c30c1c4584bf2b909cb503f72c",
              "IPY_MODEL_9475ecfb06444fe3b8e295f29e157115",
              "IPY_MODEL_c6cb0e00b0754cfd8bb5c2d3e4be23c8"
            ],
            "layout": "IPY_MODEL_178855b63dfe4ab69c87509953e45d78"
          }
        },
        "201f52c30c1c4584bf2b909cb503f72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7718eec277e40f89a9fdaff15ea2fad",
            "placeholder": "​",
            "style": "IPY_MODEL_27260582510c4eac9a7527412d6c981d",
            "value": "Downloading 1 files: 100%"
          }
        },
        "9475ecfb06444fe3b8e295f29e157115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e6f38cb60f4d1c8b863e3c757292fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4b28902880540d39c35fcd62c13a590",
            "value": 1
          }
        },
        "c6cb0e00b0754cfd8bb5c2d3e4be23c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da90197ffce4bc3ab5c786afbe78cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_c5877353e91f4fd19cd667383bfa1476",
            "value": " 1/1 [00:00&lt;00:00,  1.50it/s]"
          }
        },
        "178855b63dfe4ab69c87509953e45d78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7718eec277e40f89a9fdaff15ea2fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27260582510c4eac9a7527412d6c981d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e6f38cb60f4d1c8b863e3c757292fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b28902880540d39c35fcd62c13a590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1da90197ffce4bc3ab5c786afbe78cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5877353e91f4fd19cd667383bfa1476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}